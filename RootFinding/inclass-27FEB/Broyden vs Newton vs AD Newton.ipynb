{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: comparing Broyden to Automatic Differentiation\n",
    "By T. Fitzgerald\n",
    "\n",
    "We'll be solving the same system of equations that we worked on during the previous class\n",
    "$$ \\frac{x^2}{4} + y^2 = 1 $$\n",
    "$$ y = 0.7x^4 + 0.1x^3 - 2.5x^2 + 1 $$\n",
    "\n",
    "I'll use several packages to help with this: [ForwardDiff.jl](http://www.juliadiff.org/ForwardDiff.jl/stable/) and [BenchmarkTools.jl](https://github.com/JuliaCI/BenchmarkTools.jl).  ForwardDiff is an automatic differentiation library that very efficiently (and robustly) computes the derivatives of a function.  I'm using BenchmarkTools to help gauge how expensive the relative methods are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\")\n",
    "using LinearAlgebra\n",
    "using ForwardDiff\n",
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the same functions as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p(x) = 0.7x^4 + 0.1x^3 - 2.5x^2 + 1\n",
    "f1(z) = z[1]^2/4 + z[2]^2 - 1\n",
    "f2(z) = p(z[1]) - z[2]\n",
    "f(z) = [f1(z), f2(z)]\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the full Jacobian, for use with Newton's method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       "  0.5   2.0\n",
       " -1.9  -1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function Jt(z)\n",
    "    x = z[1]\n",
    "    y = z[2]\n",
    "    Jt = zeros(2,2)\n",
    "    Jt[1,1] = x/2\n",
    "    Jt[1,2] = 2y\n",
    "    Jt[2,1] = 0.7*4*x^3 + 0.1*3*x^2 - 2.5*2*x\n",
    "    Jt[2,2] = -1\n",
    "    return Jt\n",
    "end\n",
    "Jt([1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can use the `jacobian` function of ForwardDiff to compute the multidimensional derivative of the residuals `f`, evaluated at a point `x` magically.  I'll wrap that call into a function, so I can just call that later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "∇f (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇f(x) = ForwardDiff.jacobian( f, x )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the function gives the *same* result as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       "  0.5   2.0\n",
       " -1.9  -1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇f([1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm( ∇f([-1,1]) - Jt([-1.,1]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broyden Updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "function myBroyden(x0, J0; tol = 1e-8, max_iter = 50)\n",
    "    iter = 0\n",
    "    flag = 0\n",
    "\n",
    "    # initial step\n",
    "    D = inv(J0)\n",
    "    d = -D*f(x0)\n",
    "    x1 = x0 + d\n",
    "    F = f(x1)\n",
    "    \n",
    "    while flag == 0\n",
    "\n",
    "        u = D*F\n",
    "        c = d'*( d + u )\n",
    "        D -= 1/c*(u*d')*D   \n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        d = -D*F\n",
    "        x1 = x1 + d\n",
    "        F = f(x1)\n",
    "        \n",
    "        err = norm(F)\n",
    "\n",
    "        if err <= tol\n",
    "            flag = 1\n",
    "\n",
    "        elseif iter >= max_iter\n",
    "            flag = -1\n",
    "            \n",
    "        end  \n",
    "\n",
    "    end\n",
    "    \n",
    "    return x1, flag, iter\n",
    "    \n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newton's Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myNewton (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function myNewton(x0; tol = 1e-8, max_iter = 50)\n",
    "    iter = 0\n",
    "    flag = 0\n",
    "\n",
    "    x1 = copy(x0)\n",
    "    F = f(x1)\n",
    "    while flag == 0\n",
    "\n",
    "        iter += 1\n",
    "        J = Jt(x1) # using the full jacobian\n",
    "        x1 -= J\\F\n",
    "        F = f(x1)\n",
    "        \n",
    "        err = norm(F)\n",
    "\n",
    "        if err <= tol\n",
    "            flag = 1\n",
    "\n",
    "        elseif iter >= max_iter\n",
    "            flag = -1\n",
    "            \n",
    "        end  \n",
    "\n",
    "    end\n",
    "    \n",
    "    return x1, flag, iter\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newton's method with approximate Jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "function myADNewton(x0; tol = 1e-8, max_iter = 50)\n",
    "    iter = 0\n",
    "    flag = 0\n",
    "\n",
    "    x1 = copy(x0)\n",
    "    F = f(x1)\n",
    "    while flag == 0\n",
    "\n",
    "        iter += 1\n",
    "        J = ∇f(x1) # this is the AD step\n",
    "        x1 -= J\\F\n",
    "        F = f(x1)\n",
    "        \n",
    "        err = norm(F)\n",
    "\n",
    "        if err <= tol\n",
    "            flag = 1\n",
    "\n",
    "        elseif iter >= max_iter\n",
    "            flag = -1\n",
    "            \n",
    "        end  \n",
    "\n",
    "    end\n",
    "    \n",
    "    return x1, flag, iter\n",
    "    \n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing time\n",
    "First, let's assume the same initial guess for all three methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = [2,-2];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.53561, -0.640681], 1, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myNewton(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.53561, -0.640681], 1, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myADNewton(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.53561, -0.640681], 1, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute Jacobian by finite differences\n",
    "ε = 1e-2\n",
    "J0 = zeros(2,2)\n",
    "J0[:,1] = ( f(x0 + ε*[1,0]) - f(x0) )/ε\n",
    "J0[:,2] = ( f(x0 + ε*[0,1]) - f(x0) )/ε\n",
    "myBroyden(x0, J0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that all 3 methods converged.  Also, the number of steps for full Newton and AD Newton are the same. Broyden was only slightly slower with several additional steps.  But we know that, in general, the cost per step is lower so the overall costs are all nearly the same.  \n",
    "\n",
    "To help look in to the timings of each method, I'm going to use the BenchmarkTools.jl package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  3.34 KiB\n",
       "  allocs estimate:  38\n",
       "  --------------\n",
       "  minimum time:     2.944 μs (0.00% GC)\n",
       "  median time:      4.500 μs (0.00% GC)\n",
       "  mean time:        8.091 μs (19.45% GC)\n",
       "  maximum time:     8.337 ms (99.93% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     9"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark myNewton(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  4.98 KiB\n",
       "  allocs estimate:  63\n",
       "  --------------\n",
       "  minimum time:     6.360 μs (0.00% GC)\n",
       "  median time:      7.940 μs (0.00% GC)\n",
       "  mean time:        12.618 μs (19.75% GC)\n",
       "  maximum time:     17.408 ms (99.82% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark myADNewton(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  12.22 KiB\n",
       "  allocs estimate:  121\n",
       "  --------------\n",
       "  minimum time:     6.460 μs (0.00% GC)\n",
       "  median time:      7.860 μs (0.00% GC)\n",
       "  mean time:        13.139 μs (26.69% GC)\n",
       "  maximum time:     16.834 ms (99.88% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark myBroyden(x0, J0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that Broyden is slower.  It needed more steps, so this makes perfect sense.  However, what this test problem does not show is how as the problem size increases that Broyden becomes very competitive.  Since the approximate update is to the *inverse* of the Jacobian, no linear-system needs to be inverted and that can become a dominating cost as the problem size increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
